{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe7e7399-f18d-4206-8285-18c93b070c89",
   "metadata": {},
   "source": [
    "# Image processing: Contact angle measurement and line tracking for water and Tween\n",
    "This notebook contains the image processing steps (Section 2.1.2), including\n",
    "- RANSAC fit of interface and contact angle measurement (step iii)\n",
    "- interface tracking (step iv).\n",
    "\n",
    "Note that since the processing of the Novec results require extra steps, it is given in *image_processing_novec*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfc3875-acb4-4038-b241-ffd83d29c764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "from os.path import join\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from shared_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42528dd-8c14-4d93-93b2-fc9a5f101b8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d8016d-9588-49b5-9d36-3f4674c13a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_gray_value_along_horizontal_line(gray, pos_y, start_x, end_x):\n",
    "    \"\"\"\n",
    "    Finds the minimum value (darkest pixel) along a horizontal line in a grayscale image.\n",
    "\n",
    "    Args:\n",
    "    gray (numpy.ndarray): The grayscale image.\n",
    "    pos_y (int): The y-coordinate of the horizontal line.\n",
    "    start_x (int): The starting x-coordinate of the line.\n",
    "    end_x (int): The ending x-coordinate of the line.\n",
    "\n",
    "    Returns:\n",
    "    A tuple containing the minimum greyscale value found along the line and the x-coordinate of the minimum value.\n",
    "    \"\"\"\n",
    "    # create line\n",
    "    gray_line = gray[pos_y][start_x:end_x]\n",
    "    \n",
    "    # find minimum and x position\n",
    "    min_gray = min(gray_line)\n",
    "    x_min_gray = np.where(gray_line == min_gray)[0][0]+start_x # only first occurrence is detected\n",
    "\n",
    "    return min_gray, x_min_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf0327a-affc-4273-8775-e6fe92691522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_estimator_object(fit_degree):\n",
    "    \"\"\"\n",
    "    Creates an instance of the PolynomialRegression class with the specified degree for polynomial fitting.\n",
    "\n",
    "    This wrapper function is necessary to ensure the right fitting degree.\n",
    "    In sklearn 1.2.2 it is not possible to specify the correct fit degree in ransac.fit, \n",
    "    even though the instance was created with the correct degree.\n",
    "    Therefore this class works as a workaround to force the degree.\n",
    "\n",
    "    Args:\n",
    "    fit_degree (int): degree for polynomial fitting.\n",
    "\n",
    "    Returns:\n",
    "    An instance of the PolynomialRegression class with the specified degree.\n",
    "    \"\"\"\n",
    "    \n",
    "    # create polynomial regression class with given degree, necessary as input for RANSAC fit\n",
    "    class PolynomialRegression(object):\n",
    "        def __init__(self, degree=fit_degree, coeffs=None):\n",
    "            self.degree = degree\n",
    "            self.coeffs = coeffs\n",
    "\n",
    "        def fit(self, X, y):\n",
    "            self.coeffs = np.polyfit(X.ravel(), y, self.degree)\n",
    "\n",
    "        def get_params(self, deep=True):\n",
    "            return {'coeffs': self.coeffs}\n",
    "\n",
    "        def set_params(self, coeffs=None, random_state=None):\n",
    "            self.coeffs = coeffs\n",
    "\n",
    "        def predict(self, X):\n",
    "            poly_eqn = np.poly1d(self.coeffs)\n",
    "            y_result = poly_eqn(X.ravel())\n",
    "            return y_result\n",
    "\n",
    "        def score(self, X, y):\n",
    "            return mean_squared_error(y, self.predict(X))\n",
    "        \n",
    "    return PolynomialRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba3e702-ed82-4ce4-a902-9fb01f017353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_interface_RANSAC(x_vals, y_vals, polyfit_degree, residual_threshold, min_samples):\n",
    "    \"\"\"\n",
    "    Fits the interface pixels using the RANSAC algorithm with polynomial regression.\n",
    "\n",
    "    Args:\n",
    "    x_vals (numpy.ndarray): given sample points.\n",
    "    y_vals (numpy.ndarray): points to be fitted to sample points.\n",
    "    polyfit_degree (int): degree for polynomial fitting.\n",
    "    residual_threshold (float): maximum residual for a data point to be classified as an inlier.\n",
    "    min_samples (int): The minimum number of samples required to fit the model.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the following elements:\n",
    "     - y_result (numpy.ndarray): predicted y-values of the contact line.\n",
    "     - inlier_mask (numpy.ndarray): boolean mask indicating the inliers.\n",
    "     - theta_top_deg (float): resulting contact angle at the interface top.\n",
    "     - theta_bot_deg (float): resulting contact angle at the interface bottom.\n",
    "    \"\"\"\n",
    "\n",
    "    # create regression object \n",
    "    estimator = create_estimator_object(polyfit_degree)\n",
    "    ransac = RANSACRegressor(estimator,\n",
    "                             residual_threshold= residual_threshold, \n",
    "                             random_state=0,\n",
    "                             min_samples=min_samples)\n",
    "\n",
    "    # fit data\n",
    "    ransac.fit(np.expand_dims(x_vals, axis=1), y_vals)\n",
    "    inlier_mask = ransac.inlier_mask_\n",
    "    y_result = ransac.predict(np.expand_dims(x_vals, axis=1))\n",
    "    params = ransac.estimator_.coeffs\n",
    "    \n",
    "    # compute first derivative of fitted function\n",
    "    fitted_polynomial = np.poly1d(params)\n",
    "    derivative_of_fittted_polynomial = fitted_polynomial.deriv() \n",
    "    points_of_polynomial_derivative = np.polyval(derivative_of_fittted_polynomial.c, np.sort(x_vals))\n",
    "    \n",
    "    # compute slope at the walls\n",
    "    slope_top = points_of_polynomial_derivative[0]\n",
    "    slope_bot = points_of_polynomial_derivative[-1]\n",
    "    \n",
    "    # compute contact angles     \n",
    "    theta_top_deg = math.degrees(math.atan(slope_top))\n",
    "    theta_bot_deg = math.degrees(math.atan(slope_bot))\n",
    "\n",
    "    return y_result, inlier_mask, theta_top_deg, theta_bot_deg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732d7449-f1f2-4597-a680-d377e6f74139",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (iii) Contact angle measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f358f499-bee8-4ae1-9f2c-7690fa46fb7e",
   "metadata": {},
   "source": [
    "**User input: selection of cases and general parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6229b1-bf09-4e08-9f37-59aeed62f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose fluid\n",
    "fluid =  \"01_water\" # available: 01_water, 02_tween\n",
    "\n",
    "# choose cases that should be considered\n",
    "# if empty --> all cases are used. insert 1,2,3 to choose case 1,2,3\n",
    "case_selection=[]\n",
    "\n",
    "# choose the step of processed images (1 --> every image is used)\n",
    "step_images = 1\n",
    "\n",
    "# choose which result to plot (\"all\", \"last\", \"none\") --> \"all\" leads to longer runtime.\n",
    "plot_pictures = \"last\"\n",
    "\n",
    "# choose at which point to end the analysis.\n",
    "# use \"when_cavities_are_reached\" for contact angle measurements, \"when_interface_leaves_roi\" for line tracking.\n",
    "end_analysis = \"when_cavities_are_reached\"\n",
    "\n",
    "# choose paths\n",
    "path_data_experiments = \"../data_experiments\"\n",
    "path_df_postproc = join(path_data_experiments, \"case_parameters.xlsx\")\n",
    "path_df_channel_edges = join(path_data_experiments, fluid, \"02_channel_edges\", \"df_channel_edges.csv\")\n",
    "path_images = join(path_data_experiments, fluid, \"01_images_preprocessed\")\n",
    "path_save = join(path_data_experiments, fluid, \"03_contact_angle_measurement\")\n",
    "\n",
    "# create directory for saving results and plots\n",
    "os.makedirs(path_save, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc4c582-be5d-4c0e-8625-be34c43a9a84",
   "metadata": {},
   "source": [
    "**User input: RANSAC fitting parameters.**\n",
    "- fit_degree (int): degree for polynomial fitting.\n",
    "- min_samples (int): minimum amount of considered inliers.\n",
    "- residual_threshold (int): maximum residual for a data point to be classified as an inlier during RANSAC curve fitting of the interface.\n",
    "- pre_filter_threshold (int): threshold of initial pre-filtering step.\\\n",
    "    The pre-filter removes outliers in the interface detection by removing points whose distance to both neighbors is > pre_filter_threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c32d6b0-3ba0-4b54-b35e-76862b32d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_degree = 3\n",
    "min_samples = 100\n",
    "residual_threshold = 10\n",
    "pre_filter_threshold = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a67eace-33de-40c9-aa13-49b7230e145f",
   "metadata": {},
   "source": [
    "**Run the analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e18ad-b332-49d0-a546-ac00c7637636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set case selection based on user input\n",
    "if case_selection == []:\n",
    "    cases = [int(_) for _ in os.listdir(path_images) if len(_)<3]\n",
    "else: \n",
    "    cases = case_selection\n",
    "print(f\"selected cases: {cases}\")\n",
    "\n",
    "# initialize lists for results\n",
    "list_ca_ransac_top, list_ca_ransac_bot, list_rms_dist_to_fit_ransac  = ([] for i in range(3))\n",
    "\n",
    "for case in cases:\n",
    "    \n",
    "    print(f\"Case {case}\")\n",
    "\n",
    "    # get case data\n",
    "    x_start, x_cavities, y_channelEdge_bottom, y_channelEdge_top, framerate, selected_images = get_case_parameters(fluid, case, path_df_channel_edges, path_df_postproc, path_images, step_images, end_analysis)    \n",
    "    print(f'\\t number of selected images: {len(selected_images)}')\n",
    "    \n",
    "    # initialize lists for results of this case\n",
    "    theta_ransac_top_case = []\n",
    "    theta_ransac_bot_case = []\n",
    "    \n",
    "    # rms_dist_to_fit_polyfit_case = []\n",
    "    rms_dist_to_fit_ransac_case = []\n",
    "    \n",
    "    # loop over images\n",
    "    for i in range(len(selected_images)):\n",
    "        \n",
    "        # Load the image and convert it to grayscale\n",
    "        img_name = selected_images[i]\n",
    "        image = cv2.imread(os.path.join(path_images, str(case), img_name))\n",
    "        image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # --------------- detect interface: sample lowest grayscale values along rows\n",
    "        \n",
    "        # define region of interest (upstream of cavities)\n",
    "        x_roi = [x_start, x_cavities-10] #safety distance\n",
    "        y_roi = [y_channelEdge_top, y_channelEdge_bottom]\n",
    "        \n",
    "        # initialize lists\n",
    "        y_sample_points = np.array(range(y_roi[0], y_roi[1])) \n",
    "        x_interface = np.empty(0)\n",
    "\n",
    "        # sample darkest pixels (lowest grayscale values) along horizontal lines for each y sample point\n",
    "        for y in y_sample_points:\n",
    "            (min_gray, x_min_gray) = find_min_gray_value_along_horizontal_line(image_gray, y, x_roi[0], x_roi[1])\n",
    "            x_interface = np.append(x_interface, x_min_gray)\n",
    "      \n",
    "        # -------------- pre-filter data\n",
    "        \n",
    "        # create filter: check neighbors for each sample point, remove sample points that are further \n",
    "        # away than pre_filter_threshold from both neighbors.\n",
    "        mask_filter =  np.array(len(x_interface) * [True])\n",
    "        for xi in range(1, len(x_interface)-1):\n",
    "            if abs(x_interface[xi] - x_interface[xi-1]) > pre_filter_threshold:\n",
    "                if abs(x_interface[xi] - x_interface[xi+1]) > pre_filter_threshold:\n",
    "                    mask_filter[xi] = False\n",
    "                    \n",
    "        # special treatment for edge points\n",
    "        mask_filter[0] = False if abs(x_interface[0] - x_interface[1]) > pre_filter_threshold else True\n",
    "        mask_filter[-1] = False if abs(x_interface[-1] - x_interface[-2]) > pre_filter_threshold else True\n",
    "        \n",
    "        # apply filter\n",
    "        x_filtered = np.array(x_interface)\n",
    "        x_filtered[mask_filter==False]=0\n",
    "            \n",
    "        # -------------- contact angle detection using RANSAC\n",
    "            \n",
    "        # run ransac\n",
    "        (x_fit, inlier_mask, theta_top, theta_bot) = fit_interface_RANSAC(y_sample_points, x_filtered, polyfit_degree=fit_degree, residual_threshold=residual_threshold, min_samples=min_samples)\n",
    "\n",
    "        # transform contact angles to correct coordinate system and store them\n",
    "        theta_ransac_top_case.append(90+theta_top)  \n",
    "        theta_ransac_bot_case.append(90-theta_bot)  \n",
    "        rms_dist_to_fit_ransac_case.append(np.sqrt(np.mean((x_fit[inlier_mask]-x_interface[inlier_mask])**2)))\n",
    "\n",
    "        # ----------------plot\n",
    "        plot_now = check_if_plot_now(plot_pictures, selected_images, i)       \n",
    "        if plot_now == True:\n",
    "            \n",
    "            # plot the picture\n",
    "            fig, ax = plt.subplots(figsize=(10,10))\n",
    "            ax.imshow(image_gray, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "            # plot the ROI box\n",
    "            ax.add_patch(patches.Rectangle([x_roi[0], y_roi[0]], x_roi[1]-x_roi[0], y_roi[1]-y_roi[0],  ls=\"--\", lw=1, ec=\"k\", fc=\"none\", label='roi'))\n",
    "\n",
    "            # plot sampled interface points\n",
    "            ax.plot(x_interface[inlier_mask], y_sample_points[inlier_mask], 'b.', label='sampled points')\n",
    "\n",
    "            # plot sampled outlier points\n",
    "            ax.plot(x_interface[~mask_filter], y_sample_points[~mask_filter], '+', c='red', label='pre-filtered outliers')\n",
    "            \n",
    "            # plot sampled outlier points\n",
    "            ax.plot(x_interface[~inlier_mask&mask_filter], y_sample_points[~inlier_mask&mask_filter], 'x', c='darkred', label='RANSAC outliers')\n",
    "\n",
    "            # plot fits\n",
    "            ax.plot(x_fit, y_sample_points, '-', c='cyan', label='interface fit')            \n",
    "            \n",
    "            # cosmetics\n",
    "            ax.legend(title=f'case {case}, img {img_name[-8:-4]}, \\nresulting contact angles: top {theta_top+90:.2f}°, bot {90-theta_bot:.2f}°')\n",
    "            #fig.savefig(os.path.join(path_save, f\"interface_{fluid}_{case}_{img_name[-8:-4]}.png\"), bbox_inches='tight', dpi=300)\n",
    "\n",
    "    # ---------------- store data in lists\n",
    "    \n",
    "    list_ca_ransac_top.append(theta_ransac_top_case)    \n",
    "    list_ca_ransac_bot.append(theta_ransac_bot_case)\n",
    "    list_rms_dist_to_fit_ransac.append(rms_dist_to_fit_ransac_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e679a-165b-4143-8cd6-26a639abccfe",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Store data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec8945-0291-4421-bc6c-cdef9253af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "df_measured_contactangles = pd.DataFrame(list(zip(list_ca_ransac_top, list_ca_ransac_bot, list_rms_dist_to_fit_ransac)), \n",
    "                                         index=cases, columns =['list_ca_ransac_top', 'list_ca_ransac_bot','list_rms_dist_to_fit_ransac'])\n",
    "# store dataframe as csv\n",
    "df_measured_contactangles.to_csv(join(path_save, f\"df_measured_contactangles_poly{fit_degree}_{fluid}.csv\"), index_label='case')\n",
    "\n",
    "# disply dataframe\n",
    "display(df_measured_contactangles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3444ed7-0773-4f86-b7ef-2d788ee85d6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (iv) Interface tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6018fc-a480-4fe0-9d9f-fbb34428bbd3",
   "metadata": {},
   "source": [
    "**User input: selection of cases and general parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90c6031-7174-45a3-8e0e-4b515c7ec267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose fluid\n",
    "fluid =  \"01_water\" # available: 01_water, 02_tween\n",
    "\n",
    "# choose cases that should be considered\n",
    "# if empty --> all cases are used. insert 1,2,3 to choose case 1,2,3\n",
    "case_selection = [] \n",
    "\n",
    "# choose the step of processed images (1 --> every image is used)\n",
    "step_images = 1000\n",
    "\n",
    "# choose which result to plot (\"all\", \"last\", \"none\") --> \"all\" leads to longer runtime.\n",
    "plot_pictures = \"none\"\n",
    "\n",
    "# choose at which point to end the analysis.\n",
    "# use \"when_cavities_are_reached\" for contact angle measurements, \"when_interface_leaves_roi\" for line tracking.\n",
    "end_analysis = \"at_final_image\"\n",
    "\n",
    "# choose paths\n",
    "path_data_experiments = \"../data_experiments\"\n",
    "path_df_postproc = join(path_data_experiments, \"case_parameters.xlsx\")\n",
    "path_df_channel_edges = join(path_data_experiments, fluid, \"02_channel_edges\", \"df_channel_edges.csv\")\n",
    "path_images = join(path_data_experiments, fluid, \"01_images_preprocessed\")\n",
    "path_save = join(path_data_experiments, fluid, \"04_interface_tracking\")\n",
    "\n",
    "# create directory for saving results and plots\n",
    "os.makedirs(path_save, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b198441d-8d7a-4f2a-b505-33fe902987b0",
   "metadata": {},
   "source": [
    "**User input: select position of sample lines** \\\n",
    "For water and Tween, the interface top and bottom are tracked at 0.1mm distance from the walls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e234986a-caa1-48d3-96fe-af565f60942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_y_mm = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0371b9c2-afb8-45cf-b361-a7e36fd5d68b",
   "metadata": {},
   "source": [
    "**Run analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd35950-caf0-4874-b5b0-0418e43a183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set case selection based on user imput\n",
    "if case_selection == []:\n",
    "    cases = [int(_) for _ in os.listdir(path_images) if len(_)<3]\n",
    "else: \n",
    "    cases = case_selection\n",
    "print(f\"selected cases: {cases}\")\n",
    "\n",
    "# initialize lists for results\n",
    "list_time_range = []\n",
    "list_x_min_gray_mm_top = []\n",
    "list_x_min_gray_mm_bot = []\n",
    "list_u = []\n",
    "\n",
    "# loop over cases\n",
    "for case in cases:\n",
    "    print(f\"Case {case}\")\n",
    "     \n",
    "    # get case data\n",
    "    x_start, x_cavities, y_channelEdge_bottom, y_channelEdge_top, framerate, selected_images = get_case_parameters(fluid, case, path_df_channel_edges, path_df_postproc, path_images, step_images, end_analysis)    \n",
    "    print(f'\\t number of selected images: {len(selected_images)}')\n",
    "       \n",
    "    # get velocity for storing in dataframe\n",
    "    df_postproc =  pd.read_excel(path_df_postproc, sheet_name=fluid, index_col=\"case\", skiprows=1)\n",
    "    u = df_postproc['u'][case]\n",
    "\n",
    "    # initialize lists for results of this case\n",
    "    list_time_range_case = []\n",
    "    list_x_min_gray_mm_top_case = []\n",
    "    list_x_min_gray_mm_bot_case = []\n",
    "    \n",
    "    list_min_gray_top_case =  [0]*len(selected_images)\n",
    "    list_x_min_gray_top_case =  [0]*len(selected_images)\n",
    "    \n",
    "    list_min_gray_bot_case =  [0]*len(selected_images)\n",
    "    list_x_min_gray_bot_case =  [0]*len(selected_images)\n",
    "\n",
    "    # scale sampling position from mm to px\n",
    "    width_channel_mm = 2\n",
    "    pos_y_top = int(y_channelEdge_top + pos_y_mm / width_channel_mm * abs(y_channelEdge_top - y_channelEdge_bottom))\n",
    "    pos_y_bot = int(y_channelEdge_bottom - pos_y_mm / width_channel_mm * abs(y_channelEdge_top - y_channelEdge_bottom)) \n",
    "    \n",
    "    #loop over images\n",
    "    for i in range(len(selected_images)):\n",
    "        \n",
    "        # ----- Get Image \n",
    "\n",
    "        # Load the image and convert it to grayscale\n",
    "        img_name = selected_images[i]\n",
    "        image = cv2.imread(os.path.join(path_images, str(case), img_name))\n",
    "        image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # --------------- track interface\n",
    "        # define start and stop of sampling line\n",
    "        x_sample = [x_start, len(image_gray)-x_start]\n",
    "\n",
    "        # get min greyscale value\n",
    "        (list_min_gray_top_case[i], list_x_min_gray_top_case[i]) = find_min_gray_value_along_horizontal_line(image_gray, pos_y_top, x_sample[0], x_sample[1])\n",
    "        (list_min_gray_bot_case[i], list_x_min_gray_bot_case[i]) = find_min_gray_value_along_horizontal_line(image_gray, pos_y_bot, x_sample[0], x_sample[1])\n",
    "        \n",
    "        # ---------------- plot\n",
    "        plot_now = check_if_plot_now(plot_pictures, selected_images, i)\n",
    "\n",
    "        if plot_now == True:\n",
    "\n",
    "            # plot the picture\n",
    "            fig, ax = plt.subplots(figsize=(10,10))\n",
    "            plt.imshow(image_gray, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "            # plot the sample lines\n",
    "            ax.plot(x_sample, [pos_y_top, pos_y_top], '--k', label = 'sample lines')\n",
    "            ax.plot(x_sample, [pos_y_bot, pos_y_bot], '--k')\n",
    "            \n",
    "            # plot results\n",
    "            ax.plot(list_x_min_gray_top_case[i], pos_y_top, 'x', label = 'interface pixel top')\n",
    "            ax.plot(list_x_min_gray_bot_case[i], pos_y_bot, 'x', label = 'interface pixel bottom')\n",
    "\n",
    "            # cosmetics\n",
    "            ax.legend(fancybox=False, framealpha=1.0, facecolor=[0.8,0.8,0.8], edgecolor='k', title=f\"case {case}, img {img_name[-8:-4]}\")\n",
    "    \n",
    "            # save figure\n",
    "            #fig.savefig(join(path_save, f\"interfaceTracking_{fluid}_{case}_{img_name[-8:-4]}.png\"), bbox_inches='tight', dpi=300)\n",
    "\n",
    "    # convert results to mm and seconds\n",
    "    list_x_min_gray_mm_top_case = np.array(list_x_min_gray_top_case) * width_channel_mm / abs(y_channelEdge_top - y_channelEdge_bottom)\n",
    "    list_x_min_gray_mm_bot_case = np.array(list_x_min_gray_bot_case) * width_channel_mm / abs(y_channelEdge_top - y_channelEdge_bottom)\n",
    "    list_time_range_case = range(len(list_x_min_gray_mm_top_case))/framerate   \n",
    "    \n",
    "    # add data to lists\n",
    "    list_x_min_gray_mm_top.append(list_x_min_gray_mm_top_case)    \n",
    "    list_x_min_gray_mm_bot.append(list_x_min_gray_mm_bot_case)\n",
    "    list_time_range.append(list_time_range_case)\n",
    "    list_u.append(u)\n",
    "    \n",
    "    # plot interface tracking result\n",
    "    fig2, ax2 = plt.subplots(figsize=(5,5))\n",
    "    ax2.plot(list_time_range_case, list_x_min_gray_mm_top_case,'+', label= 'top')\n",
    "    ax2.plot(list_time_range_case, list_x_min_gray_mm_bot_case,'+', label = 'bottom')\n",
    "\n",
    "    # cosmetics\n",
    "    ax2.set_xlabel('t (s)')\n",
    "    ax2.set_ylabel('x (m)')\n",
    "    ax2.legend()\n",
    "    ax2.set_title(f\"interface tracking result, case {case}\")\n",
    "    \n",
    "    #save figure\n",
    "    fig2.savefig(join(path_save, f\"interfaceTrackingResult_{fluid}_{case}.png\"), bbox_inches='tight', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6aebc2-f893-4aec-8f2d-461299e013ef",
   "metadata": {},
   "source": [
    "**store data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f54479-ffb3-4b1f-aaa1-30eaded0b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "df_interface_tracking = pd.DataFrame(list(zip(list_u, list_time_range, list_x_min_gray_mm_top, list_x_min_gray_mm_bot)), \n",
    "                                         index=cases, columns =['u', 'list_time_range', 'list_x_min_gray_mm_top', 'list_x_min_gray_mm_bot'])\n",
    "#d isplay dataframe\n",
    "display(df_interface_tracking)\n",
    "\n",
    "# save dataframe\n",
    "df_interface_tracking.to_csv(join(path_save, f\"df_interface_tracking_{fluid}.csv\"), index_label='case')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-nal7rng]",
   "language": "python",
   "name": "conda-env-.conda-nal7rng-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
